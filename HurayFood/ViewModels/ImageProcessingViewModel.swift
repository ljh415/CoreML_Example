//
//  ImageProcessingViewModel.swift
//  HurayFood
//
//  Created by Jae Ho Lee on 2/10/25.
//

import Foundation

import SwiftUI
import CoreML

class ImageProcessingViewModel: ObservableObject {
    @Published var selectedImage: UIImage? = nil
    @Published var processedImage: UIImage? = nil // bbox ê·¸ë¦° ì´ë¯¸ì§€
    @Published var detectedBoxes: [CGRect] = []
    @Published var confidenceScores: [Float] = []
    @Published var classificationResults: [String: [(String, Double)]] = [:]
    @Published var detectionInferenceTime: String = "-- ms"
    @Published var classificationInferenceTime: String = "-- ms"
    @Published var endToEndInferenceTime: String = "-- ms"
    
    // ì„ íƒí•œ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸
    func setSelectedImage(_ image: UIImage) {
        DispatchQueue.main.async {
            self.selectedImage = image
            self.processedImage = nil
        }
    }
    
    // CoreML
    func processImage(_ cgImage: CGImage) {
        let startTime = Date()
        let detectionStartTime = Date()
        
        // Step1: Object Detection
        CoreMLManager.shared.detectObjects(in: cgImage) { boxes, scores, letterboxRect in
            let detectionElapsedTime = Date().timeIntervalSince(detectionStartTime) * 1000
            DispatchQueue.main.async {
                self.detectionInferenceTime = String(format: "%.2f ms", detectionElapsedTime)
                
                if boxes.isEmpty {
                    self.endToEndInferenceTime = "No Objects detected"
                    return
                }
                // bbox ë³µì› letterbox í›„ì²˜ë¦¬
                let originalSize = CGSize(width: cgImage.width, height: cgImage.height)
                let targetSize = CGSize(width: 640, height: 640)
//                let restoredBoxes = boxes.map { box in
//                    self.restoreBoundingBox(box, from: targetSize, to: originalSize, letterboxRect: letterboxRect)
//                }
                
                self.detectedBoxes = boxes
                self.confidenceScores = scores
                self.classificationResults = [:]
                
                guard let selectedImage = self.selectedImage else {
                    print("âŒ selectedImageê°€ nilì…ë‹ˆë‹¤. classify() í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                    return
                }
                
                let classificationStartTime = Date()        // classification ì‹œì‘ ì‹œê°„
                var classificationDurations: [Double] = []  // ê°œë³„ classification ìˆ˜í–‰ ì‹œê°„
                let dispatchGroup = DispatchGroup()         // ëª¨ë“  classificationì´ ëë‚ ë•Œ ê¹Œì§€ ê¸°ë‹¤ë¦¼
                var classifiedResults: [String: [(String, Double)]] = [:]

//                 Step2: ê° bboxì— Classification
                for (index, box) in boxes.enumerated() {
                    dispatchGroup.enter()  // classifiation ì‹œì‘ ì „ì— ê·¸ë£¹ì— ì¶”ê°€
                    let objStartTime = Date()
                    
                    CoreMLManager.shared.classify(
                        cgImage: cgImage,
                        uiImageSize: selectedImage.size,
                        boundingBox: box
                    ) { label, probs in
                        DispatchQueue.main.async {
                            let elapsedTime = Date().timeIntervalSince(objStartTime) * 1000
                            classificationDurations.append(elapsedTime)
                            
                            let sortedResults = probs.sorted { $0.value > $1.value }
                                    .prefix(5)
                                    .map { ($0.key, $0.value) }
                            
                            let objectKey = String(format: "Object %02d", index + 1)
                            classifiedResults[objectKey] = sortedResults
                            dispatchGroup.leave()  // classification ì™„ë£Œ í›„ ê·¸ë£¹ì—ì„œ ì œê±°
                            }
                        }
                    }
                
                
                // ëª¨ë“  classificationì´ ëë‚œ í›„ í‰ê·  ì²˜ë¦¬ ì‹œê°„ê³¼ End-to-End ì‹œê°„ ê³„ì‚°
                dispatchGroup.notify(queue: .main) {
                    let totalClassificationTime = classificationDurations.reduce(0, +)
                    
                    let averageClassificationTime = totalClassificationTime / Double(classificationDurations.count)
                    
                    self.classificationInferenceTime = String(format: "%.2f ms", averageClassificationTime)
                    
                    let totalTime = Date().timeIntervalSince(startTime) * 1000
                    self.endToEndInferenceTime = String(format: "%.2f ms", totalTime)
                    
                    self.classificationResults = classifiedResults
                    
                    if let uiImage = self.selectedImage {
                        self.processedImage = self.drawBoundingBoxes(
                            on: uiImage,
                            boxes: boxes,
                            scores: scores,
                            results: self.classificationResults
                        )
                    }
                }
            }
        }
    }
    
//    private func restoreBoundingBox(_ bbox: CGRect, from targetSize: CGSize, to originalSize: CGSize, letterboxRect: CGRect) -> CGRect {
//        let originalWidth = originalSize.width
//        let originalHeight = originalSize.height
//        let targetWidth = targetSize.width
//        let targetHeight = targetSize.height
//
//        let scale = min(targetWidth / originalWidth, targetHeight / originalHeight)
//
//        let x = (bbox.origin.x - letterboxRect.origin.x) / scale
//        let y = (bbox.origin.y - letterboxRect.origin.y) / scale
//        let width = bbox.width / scale
//        let height = bbox.height / scale
//        
//        let restoredBox = CGRect(x: x, y: y, width: width, height: height)
//        
//        return restoredBox
//    }

    private func drawBoundingBoxes(on image: UIImage, boxes: [CGRect], scores: [Float], results: [String: [(String, Double)]]) -> UIImage? {
        let renderer = UIGraphicsImageRenderer(size: image.size)
        print("ğŸ–¼ [drawBoundingBoxes] ì´ë¯¸ì§€ í¬ê¸°: \(image.size)")
        print("ğŸ–¼ [drawBoundingBoxes] ê·¸ë ¤ì§€ëŠ” bbox ì¢Œí‘œ: \(boxes)")
        return renderer.image { ctx in
            image.draw(at: .zero)
            
            ctx.cgContext.setLineWidth(3)
            ctx.cgContext.setStrokeColor(UIColor.red.cgColor)
            
            for (i, box) in boxes.enumerated() {
                let adjustedY = image.size.height - box.origin.y - box.height
                let adjustedBox = CGRect(x: box.origin.x, y: adjustedY, width: box.width, height: box.height)
                
                ctx.cgContext.stroke(adjustedBox)
                
                // âœ… resultsì—ì„œ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°
                let objectKey = String(format: "Object %02d", i + 1)
                let classLabel = results[objectKey]?.first?.0 ?? "Unknown"
                
                let topResult = results[objectKey]?.first
                let classConfidence = topResult?.1 ?? 0.0  // Classification Confidence
                let scoreText = String(format: "%.2f", classConfidence)
                
                // âœ… í‘œì‹œí•  í…ìŠ¤íŠ¸ êµ¬ì„±
                let text = "\(classLabel) (\(scoreText))"
                
                let attributes: [NSAttributedString.Key: Any] = [
                    .font: UIFont.systemFont(ofSize: 14, weight: .bold),
                    .foregroundColor: UIColor.red
                ]
                
                // âœ… í…ìŠ¤íŠ¸ ìœ„ì¹˜ë¥¼ box ìœ„ìª½ì— ë°°ì¹˜
                let textPosition = CGPoint(x: box.origin.x, y: max(adjustedY - 20, 5))
                text.draw(at: textPosition, withAttributes: attributes)
            }
        }
    }
}
